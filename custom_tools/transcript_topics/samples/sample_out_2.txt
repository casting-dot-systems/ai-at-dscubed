Here's a breakdown of the transcript into topics and subtopics, with the raw, unedited sections:

**Topic: AI Project Assistant - Core Functionality (Memory)**

*   **Subtopic: Context Acquisition - Meeting Data**
    *   "You know, I mean, a friend, Zoom, may I Like, like, the AI that comes in Like, you can just create... You have a uni mail, Zoom. Yeah. I think there's an AI companion, and you can create a living every time, and just let it run. It sends you, like, emails you, like, a summary of the meeting. like what everyone said, tasks to do. Yeah, but the problem with that is his back, right we want to be able to custom do it. We want the raw tools, so we want to be able to get the transcript, and get the recording, and then the prompting itself. My experience isn't fine. It's just like it's already there for us. Yeah, yeah, it's there. But it doesn't integrate into anything. That's the problem. You don't want any prepackaged solutions. I meant, like, for these meetings that we don't have a solution yet to, like, Yeah, yeah, okay, yeah. But that's fine. Yeah. Yeah, we can, we can That one of the options. Did you find knowledge No. Yeah, it's somewhere. But you're gonna, like, um, you can't, you want to get, like, the API, right Like, you have to, like, save it to clout and, like... Okay. So, on topic, we're looking at a project assistant, and the main thing we focus on first is getting the context of the project into the products, right And there are at least three big places we get context, meetings, like the one we're doing now. Disco chats which was your workman. Oh, sure. And then notion. And so, if we want to orient ourselves with these three, these are, again, like, the input. So, meetings, there are three types of meetings. There's this type of meeting, we're just work shopping. There's the lectures, which are what I've just done. And then there are the Zoom meetings that you're talking about. which is, like, where we're online, and we want to have a chat. So, Zoom could be a solution for that. And so these are almost, like, three feet, almost epics, really. because they do require a lot of work. Would that be user stories 'Cause there's Wait, actually, all of this is, like, one thing, right Like, I know you're segregating the type of meetings, but, like, the solution will still be the same. Not really, 'cause the solution for this is a recording to... How is that different from, like, a lecture As a lecture, I uploaded YouTube, and it was scrape off YouTube. Or, like, 'cause I kind of really transmitted the file any other way. Like, while doing YouTube, you can just record, like, the audio. like we're doing here. Like, while doing the lecture. Um... Yeah, we could. I can split the audio. Yeah. Yeah. But it's, like, a... In the end, it's all audio files. Yeah, in the end, it's audio files, so... So, yeah, it's just really one. The capture method is slightly different, but you're right. I think the main thing is, um, order to sucks. So, from the point where there we have audio, until the end result, that's all really the same. Yeah, yeah. But then, like, before we get the audio, we had, like, different ways of getting it. Yeah. So we group that into one epic Is that what you're saying So, like, as you said, once we get the transcript, like, everything comes at the end of it is a transcript that we yet get, like, the way to get the transcript is a separate thing. Yes, yes. but then all three, like, funnel into, like, a transcript. and then it's get processed through a processing. And that's added into the database or notion or something. Yeah, right, you did most of it already. Yeah, so... So that thought's good. that possible, almost done. Into notion or into the doubles No, right now, it's just transcribing, so audio to text is done. Yeah, the audience tests. Text, just have to save it. Okay, so then, we can go one step higher, is, like, getting the audio file. Right Because then we could just use your solution first. Yeah, everything. Yeah. So, MP, I mean, this transcribes to text. Yeah. I don't know what this line is. Um, but, uh, and then... and then it gets processed... to the doubt of it. This place And then it can either go to the ocean or database. Yeah. Um, and then at the other end, we need a way to get it. But we don't want to store the rule files. Well, we will store the world finals. We also want to index over it, like a summer drive. So we need, like, the summary, the pipeline has to get the rule file, and also the summary. Raw, you mean the raw transcription Do you want to store non summary stuff Yeah, yeah. I think it's important to have the traceability to go back to the source. I'm just thinking from scalability and, like, storage, memory storage. I don't, there's no way it's an issue, no Like, uh, how much, um, like, at worst, we can story block. What would the transcription, like the size of a transcript be for, like, a one hour meeting Like memory, like text file size. You check. It shouldn't, it shouldn't be that much. right. Uh, I think one hour is, like... five thousand words, Max. Okay. I mean, in terms of words, I don't know. Yeah, I think, like, how many, like, okay, let's just do, like, a very quick calculation, right We have six months, right Yeah. That's like, let's say, 25 weeks, 25 weeks. 26 weeks later. You know, week, how many meetings are we going to have Let's say four max, so a hundred. four max, but, like, okay, let's say if we have two lectures a week. right Maybe, well, let's say one lecture a week, because we're probably not going to have, like, uh, lecture 10 meetings. And then we have to come to a decision on, if we have, like, a meeting, this is worth, like, recording its story. Like, this one is obviously a worthwhile. No, I think every meeting should be stored. Like, it's anything, but how many meetings, like, in total meeting, minute time, would we have in a week Just the roughest, like... four hours max. Yeah, four, five hours. Five hours. No, but it shouldn't be a problem, I could. Blob storage exists. It should not be a scalability issue. This is not a, it's not a very big scale. So, it's very small. So, yeah, I think from quick calculation, we just need, for six months, it'll be 8,000 minutes of video. Yeah. that we want to be able to store in anatomy. In text, text. And, like, that's, like, I think the scalability is when we get to millions. Like, it should not be a problem anytime soon. Like, we should be able to store everything this organisation generates. Like, it should not be an issue anytime soon. Um... So, there's two things here, like, one is storing it, meaningfully, so that it can be retrieved by a tool, like, all the meetings, and then there is storing it somewhere, right Like, we store it somewhere. Yeah. And then we have, like, a function that, like, strips out, like, regularly strips out the things that are imported. Okay. And that stores that. And that is accessible by a tool. Right So, which one do you want to do Do you wanna do, like, store everything, and everything is accessible via the pool Or it should be everything eventually accessible by tool. Like, I don't see a scale anytime soon, in the sense that we should be able to store, like, books worth of text, something like, it shouldn't be a problem. Um, and if it worse comes to worst, you store it in a blob story, um, so there's Google Drive, and there's a Google Drive API. So, if voice comes the worst, we can just store a bunch of these transcripts as markdown files in Google Drive, and then the twinks. Yeah, and then the tool will fetch that. So I don't think storage is an issue. No. That scalability shouldn't be an issue. unless we're dumping a bunch of stuff into the database. Yeah, so that's what I mean. Yeah, so, like, okay, so that's that's good solution. We can look at that. But even if we did dump it into the database, like, would it actually be, is it database asshole We're on the street here, like, it's 20 GB, I think, or something like that, a month. We can expand. So, say we have $20 budget, right Would that get... how much, 'cause it's post paid, like, it's not prepaid. So, maybe, okay, so, at least we can offload the transcripts to Google. Well, try to offload as much stuff here to move by responsibility. Yeah. And 'cause we, like, as a quick hand, we'll also have, like, a summary table for each of these meetings, right Yeah, yeah. And that, we should definitely store it in database. Yeah, that makes sense. So we have the raw, we have the summary. Um, and then, I think, so this is just to store the history, right That's great. Um, and then, like, there should almost, in the future, be a step where, even if it's not history, it's, like, processing it live, so, like, it converts into tasks. And, uh, mentions the relevant people who follows up. It's like a live processing. Right. So, that's what we need to capture, like, at least three types. Yep. And then... just the get should be getting the context for the project, and that means that each of these need to be associated with the project or process."

*   **Subtopic: Context Acquisition - Discord Chats**
    *   "Wait, can I, um, can I try One thing, but I'm just kidding. Another pet Yeah. Why do we want the role Why do we want the rolling of the summer And the summer No, like, yeah, where do you want the wall So we can trace back. Who's back Yeah. And, wait, can you give you a scale Like the jumping's window for a good prompt can go all the way up to, like, 25 K words, and that's a lot of words. So, we don't need to use a summary all the time. We can actually just dump a bunch of raw stuff in most of the time. at the very beginning And that's gonna give us the highest quality output. So, we wanna, when we can, we wanna just dump the raw thing in, always. Okay. Yeah, all right. Um, like, okay, so, like, the whole project that we're doing, like, yeah, um, the highest level is, like, what we call the business outcome, okay Um, and so this has now come here as, like, the, um, like, the project manager, right Yeah, I'll just call it AI project, man. And then in here, right, you have, you have three things. Right You have the... So, I'm just gonna, like, we're just gonna focus on memory right now. So, one is, like, meetings, right And then you mentioned different types of images, right So that's one of you, one, B, one, C. And then we have Discord shots, right I'm just writing it to the, it's there. And then, third is, like, motion, tosss, and events, and dogguns, and all that stuff, right So, this sounds like epics. Um, and then, like, within Discord, it's like the chats and channels. And then, we'll have, like, an equivalent diagram like this, for Discord. We'll have another thing, like, with notion, where it's, like, events, tasks, projects. Um, members, like, whatever, all the databases within notion. And then this will have its own diagram that we have to create. I think these diagrams, like, define the whole, like, epic, like, what the scope is, what a high level, right It's also easy to understand. And then for meetings, we have, as you said, like, call them lectures, or just, like, anything that's long form, we'll call it, and one person is speaking. when you say it's a lecture, Like you today. Um, all right And then, like, workshops So, this is, like, avoiding it. Like, recording this, it doesn't really get the interaction and, like, different people talking, right 'Cause in Zoom AI, if you have, like, five, six people join the Zoom call, right, it can also summarise, it knows what came, what thing came from. So that might be meaningful. But with this, we can't do that, right Because it's like a pure transcript. Technically, you can. Well, yeah, but not that. Not accurate, not accurate. Yeah, yeah. Because it would recognise different voice. Yeah, yeah, yeah. Not done. Um, and then we have, um, what was a zodiac Like, online meetings. Yeah, so, let's just say that comes under workshops. And then the solution for workshops can be two different solutions. One is, like, this, and then one is whatever tool we have for on my meal in the rest of summaries, right So, I think we'll keep the diagrams at, like, an epic level. So these are like the epics You keep the diagram at an epic level. And then these are, like, the features should not be, like, if we have three things here, and, like, two solutions, that's two features. Not three things, not three features. Does that make sense Like, features should be things we'll build out. And then, the use cases for those features, like, we build, like, something through the feature, and that feature can be used to solve for workshop meeting one type, or, like, online meetings, or lectures, and whatever. Right So, that's how we design the features, right Does that make sense And then, like, the discord, I think these are two features. Like, one is at a chat level. Like, every row is, like, a chat, right And then, um, you could probably put, like, a meta thing, like, a schema. So, like, designing the home discord model. And then notion, I think this is pretty one to one with features. So, you build this, you build that, you build that, and then maybe, like, another feature to, like, a basic notion class that, I don't know, however we build this out. I know it's already built, so there's not much left, but, um, features are, like, what we build, not what it enables. Yeah, I know. And then user stories is, like, I don't think you'll be creating music stories. I think, like, whoever is working on that epic, and, like, let's say, I'm working on, like, discord specifically. I'll sit down with, like, Lorraine, let's say, Lorraine's working, discord Angelina, right The three of us will have, like, a quick 10 minute meeting, and we'll create user stories, because we're the ones that are gonna be delivering the feature, we know our capacity, so, like, how much we're able to work, how many, like, story points we're able to provide, do all that. If we decide, you know, we prefer, if it's, like, still high level user stories or tasks, that's up to us, right So, we don't have to, like, control for that too much, and it reduces the pressure on you. Is there the epics are things that it enables The features are things that we build, and then they use the stories ourselves. Yeah Yeah. Like, exactly. Like, the epic is... I guess, like, building out meetings, right Like, it's just what it means to us. Like, it just says meetings, but what it means to us is, like, a way to get information from meetings. Same thing with discord and notion. And then, like, this AI project manager, right it needs, like, I think you've already done this, but it needs, like, one high level diagram, right And then, with, like, references to the epics in the diagram, right So, like, a three way thing, and becomes database or notion. becomes tool, becomes, like, you know, the actual prompts, and then the response to whatever. So that simple diagram. That's easy to understand, not just for us, but, like, for these guys as well. Um, yeah. Features is, okay, to build this out, what do we need to do Right And then we can, like, compartmentalise that accordingly. And, yeah, tasks just make it self defined to it. Um, like, my request to you on notion, I think it's already like this, but if it isn't, um, like, a very clear, like, one page, which is, like, um, like, whatever business outcomes we have, right at that level, and let's say we just have one, this AI project manager, and, like, the names doesn't matter, just like this concept. And you know how, like, the notion you have, like, a toggle thing And then I see, like, these three epics. And then each of these have, like, a toggle, and then I see these three features, and then those have a toggle, and if it's just, like, on, if I can see all this in one page, it's just a lot easier. to plan as well. Yeah. Oh, that makes sense, that makes sense. Now, I don't know how to create, like, a thing that you said, like, the first feature is to plan this all out, or, like, find a way to plan the solo. I don't know what you meant by that. Is that, like, we're building a bot to plan it, or, like, this meeting is the future to do this planning So, yes, I'd like to create... To create this is a lot of, there's quite a lot of admin work, like, creating this. updating the task data. That's why we built this wrong process. so that, um, a lot of the tasks in here can be updated through the description. So, like, what parts of this will we control, and we provide, and what parts will be generated from the project manager It seems good, actually. So, the top, so, so, we need the UI to create the tasks, right So, that's gonna be in Discord. It was a tough one. I swear, of course. Yeah, sorry, what you saying Wait, is this, like, fair Yeah, that's good, that's good. Okay So, like, um, I think, instead of defining it grain first, like, if we go all the way out, if you have a person that's able to understand all that, what can that person do Right And, for example, we can suggest costs to create. Mm hmm. It can ask people how they're going with their task, if they need any help. Um, as in, like, describe my update. and then route and provide an update for the managers like me. Um, and then in the future, um, if there is a feature request, especially in the code base, it will be able to create a task specifications in the sense that, uh, we're gonna have our own definition of done, right Like, what test it has to pass, where should you create the folder Maybe even do a little bit of the code review. Um... So those are kind of the opposites. So, if we even can problemize this as just being able to retrieve those information, then there's, like, a different part of the project that's the capabilities. What do we initially provide to it to start with Do we say that we want to build an AI project manager that's able to get information from Epic 1, 2, and 3 and so that you can put it into context for more meaningful responses. And then it just builds the features from there. And then we give it maybe an idea of, we also feed it context, right about how we work, who we are, Yeah, exactly. That stuff. So, but are you saying it creates the features for us Because I think the features is, like, to me, the main, the grain that is the most important thing, right Because that's, like, the stuff that we're attacking. Like, we're building for that. So either we create the features, or we provide enough context, and all that knowledge, for it to create features for us based on what we want to do. So that's, like, that's my question, like, what's the best way to do that Like, again, I think that those are all good options. once we have the context in the bronze, we can kind of see its capability. Like, it's not so much we're building it. I guess this is kind of, like, a hypothesis. It's, like, once we put all that into context, something useful is gonna be apparent to us. And one example, that would be when they're updating the task is growing. that they will, the task will, will understand the context of the task, so the updates are more meaningful. And things like, after we do a meeting like this, we uploaded through the process, and it's able to suggest a bunch of tasks, and create that for us instead of us. So, I agree with tasks, and that grain should be completely, like, outsourced to AI. It's just, like, the future is, 'cause... Yeah, that we can define the features, and, I mean, if we're recording this, then the features will be, apparently, in the transcript. Yeah, okay. Okay. So it's just, like, yeah, again, the main hypothesis is that, if we have all this in context, the features, the way that's gonna help us is gonna be apparent. Okay, but for the to set up, to start with, we're gonna do this all these ourselves, right Because we don't have them. Yeah, yeah. And then... So, one is, I think, like, the other thing I want to bring up is the second, like, business outcome that we want to provide. This whole thing is, like, like, from memory, right Like, this whole thing is all about memory and getting context, right But then what about the actual tools Once we have those contexts, for the tools itself to get memory, like, they're all, like, inter related, that's fine. But, like, do you want, like, another kind of thing for the tools we can build Yeah, so, like, I'd imagine I'd duplicate this. So that would not be an average manager with AR project manager memory, and then we duplicate it, and it would be AI project manager functions. or, like, capability that we have. Under that, we'll have the strong process. We'll have the... For example, even if there is a chat, like just a generic chapter that has all of those, I think that'll already be super helpful. Do you want to do, like, um, like, meetings, or, like, memory, and then discord memory, ocean memory, and then, like, the actual tools, um, like, separately, like, the functions. Do you want to keep it at this AI project manager level I think that that's really good. So, the air project manager, memory levels, like, just group the memory together. Okay, yeah, so we'll have, like, another thing here, so this would be memory. Yeah. And then this would be AI project functions. Right Yeah. So, no actual, like, function, was it, like, things that he's able to do Yeah, capability, yeah. Tools Nah, the tools is more technical. Yeah, capabilities. And then there's one... Yeah, I mean, that's a good start. But, uh, well, I want to show, like, I don't know what shorts. This one. All right, so, again, like, there's three main, all the way abstracted out. There is the getting information in from a lot of sources. And then we have to store it in, like, we can't call it, like, a data like, almost, right A lake house Uh, I don't know. Isn't that more structured It's more like a place where all our data is. And this is organised. such that the AI is able to retrieve it and do, like, the capabilities. Yeah, we should just store everything on data breaks, bro. But if we start that, then, like... And this difficulty about this is that it needs to be, We need to put a lot of design into it, because this is the hardest part. Because if we have a bunch of data sources, and it's all scattered everywhere, we don't have a single source of truth, it's gonna be really, really messy. So we need a constant, like, refinement of this process. Right. And then this is, like, this is where all the summary generation happens as well. because the raw dead is coming in, and then we have to generate the summary, make sure the summary is stored in a place that makes sense. So, like, this part is almost one part. Yeah. This part is almost another part. And then this part is the L.A. engine, and then it's like, the application of the window. Yeah. And if we look at, like, what these are, they're kind of... It's, like, a merge of these two. But I think it's important to keep this mental model in mind. Because that's, like, uh, because this part, again, is probably the hardest part. Getting the right information, make sure that information, it's easily accessible, and also, it's correct. But that's got to be difficult. Yes, that's like the crux of the whole database thing. Like, um, designing the pipelines, uh, like, linking things together. Yeah, so that's all in this. Let's actually pull it, like, data management. No, I think Data Lake is good. But it's more like, it's not only the place to store it, but also everything else that's involved, like, refining the data. I think the term is called makeup now. because, like, you not only, it's not only, like, a warehouse, where you do stuff, but it's also, like, like, this, this, um, yeah, data only cost us the industry. What is in here Lake House. Like, Lake House is just a subcommonent, though, like, like us. No, like, it's an end to end thing, so it's, like, the way you store it as well. Storing knows. They have describes the architecture of story, isn't that what it describes Like, the house is the warehouse, and the lake is the day delay, right So what else are you, like, what else, what's outside of it So outside of it is, um, all of our memory processing functions, generating summaries, um, the pipelines that as soon as the raw data touches this, everything else is mostly in here. So as soon as we get the MP3, like this process here, this is in here. Because this is just ingesting data, and this is processing and managing the data in a way, where, again, it's reliable, accurate, and also, it can be retrieved. here. So this is a big chunk. And there's gonna be engines here, also, as doing one of the processing.. So, like, I think the way to generate data from the raw files, that's in there. That's like, think of, think of that as like processing, right Like, as you said, that's processing. So, all of that is, like, what data bricks provide, right It's like one lake house solution where, like, you can basically have an integrated system where you get files, right Like, you can upload or in chest files in there, and you can store them into bronze layer, right And then you do processing from the bronze to silver, which includes everything that you set. Like, that is the main thing, right Brones is just, like, staging. It's holding. It's the raw air. Right After that, like, in silver, you can design systems. You can write code that generates stuff, and then ingest it into silver, right And, like, that's, like, what we call conformance, or, like, modelling. And modelling isn't just, like, okay, I have this raw data, where can I, like, put it It's also, like, processing that raw data, and then adding masks or adding, like, you know, it could be, like, AI tool that summarises something, as you said. And then, there's, like, the goal there, which is, like, typically, it doesn't have to be like this. but it's, like, the layer that usually the business sees, that's used for reporting or analytics. And it's, like, at a team level, in an enterprise. So, like, you have your own goal layer kind of thing, but we don't need that. All we care about, simplest thing is, we get all the data, we put it in somewhere, right We store it somewhere. So we have, like, a way to manage that storing system. And then we process it, and then it's in this living, breathing model that can be written into and retrieved again. right from. Yeah, so, like, what data breaks does is, like, it has that, and you can also, like, write code. There's, like, IDEs, there's ML, more, like, ML ops. if you're aware of MLObs. There's all of that, like, embedded in the thing, so that it's all in, like, one thing, right So you can literally just, in the same environment, you can store code, you can connect to kit. You can do all sorts of things. There's all these APIs that, but it's old in, like, this one system. So, um, they call that a lake house. Um, but I think, um, yeah. It's basically a data management system. That's what it makes out. Well, that's good. That's good. So, yeah, that's what we need to do, basically. As you said, like a bronze, then the silver. Can that only be excess, like, manually, like What, dun roots Yeah, yeah, and you do more of this. Uh, specifically, daughter breaks, or, like, that thing Oh, the entire silicon. What do you mean Like, it's, like, a... it's, like, a system. So, it's, like, this container, like, it's just, like, the thing that we're calling it. What do you mean, like, accessing manually Uh, no, because, like, 'cause that is supposed to, um, let's see, from my understanding of this, it's gonna help us to, like, um, manage things, and I put them into, like... Like, different sections, what we need, right Yeah, so, I think that would be... We can, like, take inspiration from things and create, like, a good data management system. Um, like, connecting to our database, playing around with it, giving tools to access it, like read and write, um, and, like, I think what's really important is, we have, like, this, as we get these sources in, right we'll have, like, a shitload of tables and views and things going around, and, like, foreign keys that are linked to each other, all these entity relationships, right And then, I think at the end of it, the way I see it, right, is, like, this flat thing, like, the way I visualise it, is, like, we have this flat thing, where it's, like, this is all the raw sources, and it's, like, here. And then, from here, there's, like, this kind of, like, almost brain of, like, different things that are linked together, right Each, like, circle, each node is, like, a table that's linked, and, like, you know, they're linked together like this, right And there's, like, clusters, so this could be, like, specifically the discord cluster, right They're all linked together. and then, like, the notion cluster, and then clusters can have links to each other. Right But the thing is, we need to prioritise, like, speed of retrieval. As this goes up, and we dump in a lot of, like, we put in everything we have into this huge thing, we can only retrieve so much, right Like, the context window is huge, but, um, it's, like, imagine for the best possible context, We need something from here, something from this cluster, which is like, let's say, Discord, chats about the event. Um, but getting on, say, say, man. Um, and then this is, like, about the person themselves, and this is about where tossed, right So, like, queries these three clusters. Yeah. And so, this line that I'm drawing, right This thing that, like, we can define a specific tool in the repo class. right That wants to get this, like, specific combination of clusters. You've done this gold, that's... So this is generally gold, right And gold is not, like, a, it's like, it's a view. It's a view, right So all you're doing is you're creating a query, right And you're just it's like creating a query. Like, in the repo class, you don't want, like, a get... And this is what's there right now, in databased on high five. Like again, something that's, like, fairly complicated. You don't want it to be, like, 300 lines. Right You want to manage that sequel statement, that sequel query, somewhere else. And you want to, like, you then, in this, get, like, that sequel query can just be a view, right in the gold, and you can just be, like, select, star, from gold, that view, right where the discord ID equals that. So, from this cold view, it adds a filter from this specific person, or whoever, and then it gets that. So that's, like, this is, like, the medallion architecture, right Because at least that's how we're applying it outside of data analytics and reporting and into AI context. Retrieval. Then we have, like, set functions. AI set functions as tools. that they go straight here. Right And they, like, update certain tables. And that's what, this is, for example, this is a good example would be, like, the checkup table. Right So it's updated stuff in the checkup table, and it does that. So, like, this is, um, the way, like, this is, like, the generation, and, like, maybe the generation of this table, which is dependent on this table, is, like, a meeting summary, or, like, it's, like, this is, like, the raw, not raw, but it's, like, all the chats, conform in a model, right, in a good table. But then, we want to create, like, a summary table, 'cause we don't want to call, like, a function that summarises every time a session is open, right So, the generation of that table is, like, the pipeline. So each table has, like, a pipeline, right Each, like, node here has a pipeline and how it came about, right You have, like, oh, the, like, the actual data source, whether that's discord, and then the equivalent, like, bronze table that it came from. and then, like, the dependent silver tables. So within silver, you can have, like, dependencies. Right You can have like, okay, this table is dependent on this table, which is dependent on this table. And the Yamo file, like, that we run the pipeline, we can control the dependency and the ingestion of that. Right Like, this one is a summary of this, which is, like, a subset of this or something like that, right And so we have the processing and the conformance and the modelling in here. We have the ability to write into here, not just from bronze, which is like our huge, like, ingestion patterns. but also from the AI tools, based on, you know, that. And then, we also have, like, for really complex things, that we're gonna keep on running, we wanna be able to just think of it as, like, modularising it, right And so, and put it into this gold view. and that we use. Now, sometimes, it could make sense, depending on the situation, where you can retrieve straight from silver. If it's just, like, a whole table with a select statement, makes sense. We don't have to create a gold view for it. Right So, it's flexible between these two. Um, 'cause I do notice in the application, a lot of the logic is done in the application. Like, we have to fashion the discord, ID first, in an application logic step. and then use that to join it with, so, like, in the application, some of this processing does happen, as well. Oh, like, you're saying, uh, okay, okay, okay. So, maybe there's, but that's another tool, right to get the Discord ID Yes, it would be, like, tool, after tool, after tool. Yeah. So, in that case, that would be a good example of looking straight at some... Yeah, exactly. So that's why I drew this as well. In some cases, it makes sense to do that. That's flexible. And, I guess, the design of, or the decisioning of when to take it from, when to make it cold, and when to not, I think that's the best example. That depends on, yeah, the context. And yeah, like, that is, this whole thing is, like, now, we have to solve for this part, right for most of these sources. This whole thing is, like, the management, the database. Yes, yes. So, everything in here, including these pipelines. Mm. And then, here, we'll get mixed a bit with the capabilities. Yeah, yeah, yeah. Yep. And then, yeah, yeah. The only thing I would add is, here, this layer is not just our postgress. It's also our Google Drive, our notion, our discord, sometimes requiring live. don't have to query from our database. Sometimes we're very live. Okay. Yeah. Yeah. So, notion is, like, another kind of thing. Yeah, yeah. And the thing with notion is, like, um, so, so, let's say, like, this section is, like, our post-crest database. right And then this section is an ocean. And, like, this, there's no real tables here. Like, maybe I'll pick another example. This is just, like, notion here, right And when we call the ocean tools and the API and all that, we can get, like, a notion ID for this task. And that notion ID, the connection between the notion ID and the rest of this database exists in, like, this bridge table, right So we want to be able to connect things that we get from notion to the rest of the database. from different databases. Yes. Right And so, like, each database will have, like, a bridge function or, like, one, essentially, like, if you have three things, right If you have three things, these lines are, like, the number of bridges that you need, right Sometimes you just need, like, one table with one meta table with, like, at a user level, all the specific IDs. So, like, their ID in notion, their discords. Yeah, there are specific discord, and then maybe there are specific, like, Google Doc, like, if there's a Google Doc document, like, you know, that can be extended. And fact, the long we have right now. Yeah. So this will be, like, comedy time. Come think of the right word, but, yeah, like, I think it's, like, the connecter between different things. So the notion would be here, Google Drive would also be here. And the thing is, like, um, with Google Drive, it's like, it exists kind of, like, here. Right Because it's like the raw source. Are we gonna process that raw source Yeah, we can't. Like, like, it's more of a, again, into a new du Google dog. Yeah, like, we can do that. It's more of an architecture thing, not so much of an entity. These groups, right Like, this circle you group Mm hmm. Like, this is represents postgress, and that this represents no shit. Yeah. And above that, in another layer, is the semantic meaning of these groups. And so, the Google Drive will be a blonde, and then there's a subset, which is the raw, and the subset, which is the process. Yeah, so, so, that raw would be here. And then, in our diagram, we could just couple, like, the process, just in this silver layer. Right So, do you get what I mean No, no, no, because these are concepts. These are concepts. These aren't like things. Oh no, but we need things in here. because we don't store, like, this just talks about getting data up here. So, you should be, like, things and Okay, wait. As in, like, this Yeah, this raw stuff needs to be able to be retreated. Okay, okay. Yeah, so the nuts in... All right. So, if there's a thing that you want to retrieve, it'll be here. Yeah, yeah, right This is just for us and our pipelines. So then, okay, let's say we have this raw Google file, and then the summary or the processing. Which is kind of like this, right Yeah. It was like that pipeline. Like, this is dependent on this one. So, we can have, like, but this is, like, the bronze, like, the medallion kind of concept, right In the database, it's this stuff, all the stuff is held in the silver schema of the database. And then you have bronze schema, and then you might have a goal. But that's just how to, like, differentiate. But then, does this make sense Yeah, totally. Any questions here Yeah. Um... Oh, you mentioned a bronze schema, but we don't have electric. We don't have that anymore. We have a bronze. You have a... Is it just putting everything, like, from the pipeline that we use, like, for example, the discord script Like, you've created the script. Like, like, literally the discord, like, raw files that you guess Yeah. Um, that was just, like, it's just, like, name and, like, however, it's from the Discord API, right However it comes through, and then you write, like, an extractor, a pipeline thing that you've done. to put it into a table. But then from Discord API, it doesn't really make sense. Like, the name, like, that hasn't, there's no link yet to our silver thing. So, from going from there to, like, a way that it makes sense for a tool to call, and for it to connect to the rest of the database, that's the silver there. Okay. We do have, like, a bronze schema, it's just, like, you know how, like, in databases, you have, like, the actual database, Sometimes the catalogue, and then you have, like, schemas, right And then you have tables or views in there, right And so, you have, like, a thrawn schema, a silver schema, and a gold schema, and then, you define, and created tables within those. Oh, yeah. Yeah, I remember. Schema is, like, one of those words, like, model. It can just, like, mean, like, 10 different things. But, like, here, yeah. Also, why do we need, like, access Because, for example, the notion task, right The status changes are reflected live, when they're included. Um, and we don't want to be sinking everything to the database. So, in fact, if you think about it, a notion is a database. It's just one we can interact with with the UI. Yeah, so that's what it means. And same with disco chats. Sometimes we want to retrieve the latest disco chats, and we have to sync that up to our database zone. So that's what life is. Okay, makes sense. Live is also, like, the, um... Like, you know how we... Yeah, never mind. You just said that. Yeah, we have to build that light thing. The actual way in which we... I'm just, like, really, like, um, can we store all the discord chats from yesterday, or, like, three days ago, into the prompt Yeah, yeah, that should be... That's like, what, like, 1,000 words Is that a good solution, or do we... Call that, and then find a, like, the tool to, like, the tool, the extraction, that extracts discord, right Um, that's given to that you bought, like, during the session, right If it needs to get, let's say, like, the last time we've ingested Discord chats was, um, three days ago. Right So this is three days ago. T minus three. And this is T, right And then, let's say today is, like, when the session opens. Obviously, it's got all from T minus three in the database right now, somewhere here, but then to get this, which is not anywhere, it requires, like, a discord tool, extraction tool. It gets everything from here. My question is, um, how do we, like, now that, let's say, the tool's output is there, do we feed that output into the prompt, or do we kind of process, or filter for something For example, it discord ID, right To filter for that, we have to spread store it into some data structure, not like a string. We have to store it into, like, a data frame, or, like, put it into a table, like, a tempt table somewhere here. That would be a DF, like a DF. Like, in the application, we don't have to, like, upload it into history. Okay. So, this will never be put into the database. Yeah. It will just exist in the session. Yeah, exist in the session. And hopefully, hopefully, we can get us to that end. It doesn't need to return that much. We also want, um, so, this is something that we can build in. Like, this is one of those quality of life things we can implement while knowing this. So, if this is querying this tool, right, in this session, and then, we have a way to estimate the size of the data frame, if it's, like, large, then that's an indication that can settle for trigger to say, maybe we need to do another manual load into the database. Right So, that's one of those things that we can easily build. It can be a notification to our sport can trigger it automatically, right So, yeah, we have to think, like, those are things that we have to think about while designing this. You know, if the load, if this team minus three thing, the three days here, that the load isn't that high, we don't need to load anything in. We can just follow our ingestion pattern. Yeah. But if it is big, then, yeah, we can... Well, so we can just, like, ingest right after the session. 'Cause we already have the data in the application. No If two people concur in sessions... No, because you would luck, right They were, like, um... Yeah, I guess we could think. It's much easier. Like, the tool, the tool call is, like, very simple, right Like, we don't have to append this into the existing database. That's way more complicated than if we just go, Okay, at tea, get everything. Put it in the thing. Yeah. Anyway, like, this is what we call, like, full loads. right And then this is, like, this delta thing. Except I'm hesitant to call it a delta load, because we're not actually loading it anymore. It's just in the application itself. So, it's not, like, a temp table, it's just ingesting. Yeah, Nathan's saying, like, in a data frame, and maybe we can just filter by the Discord ID of the user. But, again, like, that tool has to get really good and matured. The tool to extract discord chats, 'cause there has to be some problems applied in it to put it into a daughter frame in the first place, right Yeah. We kind of just, like, or we can just dump everything as a string into, like, context. Yeah. All right. Does that make sense I think that's it. I think that's it. This is, um... everything to do with memory... is in this brain, this thing. We should really call it right. I think it does look like it right. It's 'cause I started drawing notes in that. Neural network No it's good to see you. It took love. Like fleshies. All right, so how do we, how do we deal with it So... It is a brain, right Like, you get new information, stored somehow in a neural network, and then it's retrieved when you are thinking about something, or trying to remember something. How do we build If you could drop something... What's first So... I think we need a separate I think two people dedicated, not to this, but to this, like, getting the shit in into the bronze layer. Magician, right Into, like, a very simple table. It doesn't matter how it looks. Meaning, like, it can be raw, but clean text, right Raw meaning, like, there's no, like, data quality issues. blood processes. But it's not, like, meaningfully processed, yeah. So, you could just, like, it's, like, a very simple reading thing, right And your API or your thing, your function is just, like, it gets the name, the people attended, it has, like, something, right Like, from that one meeting, you could have two different bronze tables. One is, like, the attendees. Right And every time it happens, one more thing about bronze that I've mentioned before is, like, we don't want to store history here. Like, history is somehow conformed and, like, join here. This is like a temple, hot loading, staging thing. where every time it's called, it, like, wipes everything in this table, and then puts this new stuff in, and then the silver pipeline is run. Right All that stuff flows into the existing memory, right There is a store somewhere. like, nothing permanent in the bronze layer. Yeah, correct. Correct. It's just, like, every time you call the API and you get a response, you put that in a table, right You put that in a bronze table, and then, that's basically, like, you're at the first step, right Like, you have all the ingredients in a factory, you package it together, not meaningfully, but you put it into, like, this thing, and then, you know, the, the, I don't know what it's called, but it keeps going to the next thing. And the next guy takes this package, like, gift wraps it, like, does all this, like, fancy, cool stuff that makes it useable, or, like, presentable. And then that's stored here. Then, at that moment, where you're, like, putting stuff together, it comes in, you put stuff together, you store it in the table, and then it goes out. It's done. Right Now, we will keep it in until another one comes. And the way that's, the way that's, it's called, like, truncate, truncating is, like, the table exists, but the data within it, like, the definition of the table, the call of the data types exist, right But then, when you trunk it a table, you just remove the data, and you put it back in. So we cleared the table every time we want to ingest. Yeah. So, it's just new data every time. In Bronx, yeah. So, we start from, you know, treating the data. That's the first step. Yeah, so, I, like, to be honest, I think this stuff, um, I, like, how much is already done So, Discord, I think, we have a way, like, Lorraine's worked a way to get chats and channels in. Obviously, we have to like get it really good. that tool itself, because that tool is not just going to be used. We don't want to build two duels, right You want to build a tool where either it can do this, or it can get everything. It's the same tool, right It's gonna be, like, almost redundant, except, like, the date filter, on the actual messages, right So we have to figure out how to do that. And then we have to figure out the channels. once you get that raw, like, string output, or whatever format the API gets it in, like, how do you put it into a table in bronze Right So, that's still there for discord But we've done the big thing, which is, like, Lorenzo and the big thing, which is, like, distracting that stuff. Okay, okay. Um, for notion, obviously, we have, like, a way to get tusks, but I think that's it for now. I don't know about others. there's quite a bit to do. more functions. So, like, how do we, like, how do we go about defining this So, if we grew together, but you're working on the discourse stuff, and then I can do the notion stuff. And then... As in, like, how do we, um, define the stories You were talking about the in the workshop, right You define the user stories and the tasks. How do we go about doing that right now Um, so, we start, like, um, because we don't have, I don't know what you've done so far, but we always start high level, right So we create these epics, right in ocean, and then the ways in which we deliver this, So, for, like, meetings, like, what do we actually need to do here What do we need to build out, and what do we need to shift, so that we can finish, like, getting new ticks And meetings is, like, end to end, right It's not just getting this stuff in. like, conforming it, and then retrieving it, and then, yeah, like, that's pretty much it. So, that's probably how I would define the features. So, like, for meetings, it would be, um, getting lecture, like, getting, um..."

*   **Subtopic: Context Acquisition - Notion Data**
    *   "What do you think Uh, I don't know what's already built, but, um, a way, like, a system to, and we have to figure this out, but, like, a system to go from audio recordings, storing those audio recordings, 'cause they can't just be on our local laptops, and, like, who's laptop and who's running these things Right So, all of that has to be, like, systemized, that's systematically done. Um, and then generating the text from those audios, and then, uh, storing it in bronze, conforming it, and then, you know, retrieving it. Those are all, like, things, right And as in, how do we, what takes place, would that to be defined Right now, maybe we split to groups. Um, yeah. Um, like, the actual process of getting it done. I think, in my experience at work, we literally just sit down. One guy shares a screen, and we go, epic by epic, more feature by feature, and create that shit. Hold on. It's a bit of grunt work. but this is, like, long term planning, right This is, like, planning for, I don't know, however long it's like to do this whole thing. Now, the tasks themselves will leave empty for now. We only define tasks for, or, we can define, like, future tasks, but the priority is creating tasks for, um, like, the sprint, which is, like, everything. Yeah. Should we do that now, though Yeah, so, um, I don't know if anything about, like, getting it in here. I think, like, I can work on setting the task. Can you, like, can you just create these epics Yeah, yeah, I can do that. I could do that. And then, um, within each epic, um, we can do, like, two groups, so I will do, like, I will define features to get this done. Right Like, the actual, like, this stuff, I will define features for each of these epics. Um, yeah. Obviously, like, it's not, we don't have, like, bronze epic silver epic gold epic. We want to retain, like, this will always exist. We will never complete this, right It's like a continuing thing. of these things we can finish. So that's how we define epics, right Things that have, like, a lifespan. So, this one, you will, um, this one will have, like, bronze, silver, and gold elements. This one will have broad silver, gold, and, like, extraction elements. This one will, either way. So, if you create that epic first, and then maybe this one is, well, like, at that business outcome level. And then, for each of those epics, we schedule a time to define them out. for the people who were in the group. So, like, we, a couple people work on each epic and then, like, amongst themselves, there'll be one product manager that was scheduled the meetings, and then worked it out in that time. Yep. And with, like, planning, like, due dates, it's typically, like, the last thing you do. Well, actually, the second last thing is, like, allocating people to things. But you wanna have a good idea of how long it will take to, like, build out a feature. Like, a very, like, basic estimate, like, this thing will take, um, you know, two weeks to do, which is, like, 10, like, 14 story points. Right One story point. I don't know how it's, I don't know if you want to go down, like, full planning, like, story estimates, and effort estimation, and shit like that, where, basically, at each feature, you have a number on number of days it takes to finish. And then,"